# ğŸ“¦ [í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜]
# pip install openai python-dotenv sounddevice scipy numpy playsound fpdf2

import json  # ğŸ“„ ë°ì´í„° ì²˜ë¦¬
import random  # ğŸ² ëœë¤ ë½‘ê¸°
from openai import OpenAI  # ğŸ¤– AI ëª¨ë¸ ì—°ê²°
from dotenv import load_dotenv  # ğŸ” API í‚¤ ë¡œë“œ
import os  # ğŸ’» ì‹œìŠ¤í…œ ì œì–´
import sounddevice as sd  # ğŸ¤ ë…¹ìŒ
import scipy.io.wavfile as wav  # ğŸ¼ WAV íŒŒì¼ ì €ì¥
import numpy as np  # ğŸ§® ìˆ˜ì¹˜ ê³„ì‚°
import time  # â±ï¸ ì‹œê°„ ì œì–´
from datetime import datetime  # ğŸ“… [NEW] ë‚ ì§œì™€ ì‹œê°„ì„ ê¸°ë¡í•˜ê¸° ìœ„í•´ ì¶”ê°€
from playsound import playsound  # ğŸ”Š ì†Œë¦¬ ì¬ìƒ
from fpdf import FPDF  # ğŸ“‘ PDF ìƒì„±

# ------------------------------------------------------------
# 0. ì„¤ì • ë° ì´ˆê¸°í™”
# ------------------------------------------------------------
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ’¾ [NEW] ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•  íŒŒì¼ ì´ë¦„
LOG_FILE = "conversation_log.txt"

# ------------------------------------------------------------
# 1. [NEW] ëŒ€í™” ì €ì¥ í•¨ìˆ˜ (í•µì‹¬ ì¶”ê°€ ê¸°ëŠ¥)
# ------------------------------------------------------------
def save_conversation(user_text, ai_text):
    """
    ğŸ—£ï¸ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ AIì˜ ë‹µë³€ì„ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì´ì–´ë¶™ì—¬ ì €ì¥(Append)í•©ë‹ˆë‹¤.
    """
    # ğŸ•’ í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ êµ¬í•˜ê¸° (ì˜ˆ: 2025-12-21 14:30:05)
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # ğŸ“ ì €ì¥í•  í˜•ì‹ ë§Œë“¤ê¸°
    log_content = f"[{now}]\nğŸ‘¤ ì‚¬ìš©ì: {user_text}\nğŸ¤– AI: {ai_text}\n" + "-"*50 + "\n"
    
    try:
        # ğŸ“‚ íŒŒì¼ì„ 'ì´ì–´ì“°ê¸° ëª¨ë“œ(a)'ë¡œ ì—½ë‹ˆë‹¤. (utf-8 ì¸ì½”ë”© í•„ìˆ˜)
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(log_content)
        print(f"ğŸ’¾ [System] ëŒ€í™” ë‚´ìš©ì´ '{LOG_FILE}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")

# ------------------------------------------------------------
# 2. ë„êµ¬(í•¨ìˆ˜) ì •ì˜
# ------------------------------------------------------------
def get_current_weather(location, unit="celsius"):
    """ [ì‹œë®¬ë ˆì´ì…˜] ë‚ ì”¨ ì¡°íšŒ """
    print(f"ğŸ•µï¸ [System] '{location}' ë‚ ì”¨ ì¡°íšŒ ì¤‘...")
    conditions = ["ë§‘ìŒ â˜€ï¸", "íë¦¼ â˜ï¸", "ë¹„ ğŸŒ§ï¸", "ëˆˆ â„ï¸"]
    return json.dumps({
        "location": location,
        "temperature": random.randint(-5, 30),
        "condition": random.choice(conditions)
    })

def get_latest_news(topic="general"):
    """ [ì‹œë®¬ë ˆì´ì…˜] ë‰´ìŠ¤ ê²€ìƒ‰ """
    print(f"ğŸ•µï¸ [System] '{topic}' ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
    fake_headlines = [
        f"ì†ë³´: {topic} ì‹œì¥ì˜ ë†€ë¼ìš´ ë³€í™”",
        f"{topic} ê¸°ìˆ , ë¯¸ë˜ë¥¼ ì–´ë–»ê²Œ ë°”ê¿€ê¹Œ?",
        f"ì „ ì„¸ê³„ê°€ ì£¼ëª©í•˜ëŠ” {topic} íŠ¸ë Œë“œ",
        f"ì „ë¬¸ê°€ë“¤, '{topic}'ì— ëŒ€í•œ ê¸ì •ì  ì „ë§"
    ]
    return json.dumps({
        "topic": topic,
        "headlines": random.sample(fake_headlines, 3)
    })

def create_pdf_report(title, content):
    """ [PDF ìƒì„±] ë³´ê³ ì„œ ë§Œë“¤ê¸° """
    print(f"ğŸ–¨ï¸ [System] PDF ìƒì„± ì¤‘... (ì œëª©: {title})")
    filename = f"Report_{int(time.time())}.pdf"
    
    try:
        pdf = FPDF()
        pdf.add_page()
        # ìœˆë„ìš° í°íŠ¸ ê²½ë¡œ (ë§¥ì€ ë³€ê²½ í•„ìš”)
        font_path = "C:/Windows/Fonts/malgun.ttf"
        
        if os.path.exists(font_path):
            pdf.add_font("Malgun", fname=font_path)
            pdf.set_font("Malgun", size=12)
        else:
            pdf.set_font("Helvetica", size=12)

        # ì œëª©
        pdf.set_font_size(16)
        pdf.cell(0, 10, text=f"Report: {title}", new_x="LMARGIN", new_y="NEXT", align='C')
        pdf.ln(10)
        
        # ë³¸ë¬¸
        pdf.set_font_size(11)
        pdf.multi_cell(0, 8, text=content)
        
        pdf.output(filename)
        print(f"âœ… PDF ì €ì¥ ì™„ë£Œ: {filename}")
        return json.dumps({"status": "success", "filename": filename})

    except Exception as e:
        print(f"âŒ PDF ìƒì„± ì‹¤íŒ¨: {e}")
        return json.dumps({"status": "error", "error": str(e)})

# ------------------------------------------------------------
# 3. ë„êµ¬ ìŠ¤í‚¤ë§ˆ
# ------------------------------------------------------------
tools_schema = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "ì§€ì—­ ë‚ ì”¨ ì¡°íšŒ",
            "parameters": {
                "type": "object",
                "properties": {"location": {"type": "string"}},
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_latest_news",
            "description": "ë‰´ìŠ¤ í‚¤ì›Œë“œ ê²€ìƒ‰",
            "parameters": {
                "type": "object",
                "properties": {"topic": {"type": "string"}},
                "required": ["topic"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "create_pdf_report",
            "description": "ì •ë³´ë¥¼ PDF íŒŒì¼ë¡œ ì €ì¥",
            "parameters": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "content": {"type": "string"}
                },
                "required": ["title", "content"]
            }
        }
    }
]

# ------------------------------------------------------------
# 4. ìŠ¤ë§ˆíŠ¸ ë…¹ìŒ (VAD)
# ------------------------------------------------------------
def record_voice_smart(filename="input.wav", fs=16000, silence_threshold=150, silence_duration=1.2):
    """ ğŸ¤ ë§í•  ë•Œë§Œ ë…¹ìŒí•˜ëŠ” ë˜‘ë˜‘í•œ ê·€ """
    print("\nğŸ‘‚ ë“£ê³  ìˆì–´ìš”... (ë§ì”€í•˜ì‹œë©´ ë…¹ìŒ ì‹œì‘)")
    
    buffer = []
    recording = True
    voice_detected = False
    silence_start_time = None
    
    with sd.InputStream(samplerate=fs, channels=1, dtype="int16") as stream:
        while recording:
            frame, _ = stream.read(int(0.1 * fs))
            volume = np.sqrt(np.mean(frame.astype(np.float64)**2))
            
            if volume > silence_threshold:
                if not voice_detected:
                    print("ğŸ—£ï¸ ê°ì§€ë¨! ë…¹ìŒ ì¤‘...")
                    voice_detected = True
                silence_start_time = None
                buffer.append(frame)
                
            else:
                if voice_detected:
                    if silence_start_time is None: silence_start_time = time.time()
                    buffer.append(frame)
                    
                    if time.time() - silence_start_time > silence_duration:
                        print("âœ… ë…¹ìŒ ì¢…ë£Œ.")
                        recording = False

    if buffer:
        wav.write(filename, fs, np.concatenate(buffer, axis=0))
        return filename
    return None

def speech_to_text(file_path):
    """ ğŸ“ ìŒì„± -> í…ìŠ¤íŠ¸ ë³€í™˜ """
    if not os.path.exists(file_path): return ""
    try:
        with open(file_path, "rb") as f:
            return client.audio.transcriptions.create(model="whisper-1", file=f, language="ko").text
    except: return ""

# ------------------------------------------------------------
# 5. GPT ë‡Œ (ìƒê° + ë„êµ¬ ì‹¤í–‰)
# ------------------------------------------------------------
def ask_gpt(question):
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ AI ë¹„ì„œì…ë‹ˆë‹¤. PDF ì €ì¥ì„ ìš”ì²­ë°›ìœ¼ë©´ ê²€ìƒ‰ í›„ ìš”ì•½í•˜ì—¬ ë¬¸ì„œë¥¼ ë§Œë“œì„¸ìš”."},
        {"role": "user", "content": question}
    ]

    try:
        # 1ì°¨ ìƒê°
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            tools=tools_schema,
            tool_choice="auto"
        )
        
        response_message = response.choices[0].message
        tool_calls = response_message.tool_calls

        # ë„êµ¬ ì‚¬ìš©ì´ í•„ìš”í•˜ë©´
        if tool_calls:
            print(f"ğŸ¤– GPT: {len(tool_calls)}ê°€ì§€ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
            messages.append(response_message)

            for tool_call in tool_calls:
                fname = tool_call.function.name
                args = json.loads(tool_call.function.arguments)
                result = ""
                
                if fname == "get_current_weather":
                    result = get_current_weather(args.get("location"))
                elif fname == "get_latest_news":
                    result = get_latest_news(args.get("topic"))
                elif fname == "create_pdf_report":
                    result = create_pdf_report(args.get("title"), args.get("content"))

                messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": fname,
                    "content": result
                })

            # ìµœì¢… ë‹µë³€ ìƒì„±
            second_response = client.chat.completions.create(
                model="gpt-4o-mini", messages=messages
            )
            return second_response.choices[0].message.content
        
        else:
            return response_message.content

    except Exception as e:
        print(f"âŒ GPT ì˜¤ë¥˜: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ------------------------------------------------------------
# 6. ë©”ì¸ ì‹¤í–‰ (ì €ì¥ ê¸°ëŠ¥ í¬í•¨)
# ------------------------------------------------------------
def text_to_speech(text):
    """ ğŸ”Š í…ìŠ¤íŠ¸ -> ìŒì„± ë³€í™˜ """
    try:
        speech = client.audio.speech.create(model="tts-1", voice="nova", input=text)
        filename = f"reply_{int(time.time())}.mp3"
        with open(filename, "wb") as f: f.write(speech.read())
        return filename
    except: return None

def ai_voice_assistant():
    print("\nğŸš€ [AI ë¹„ì„œ] ê°€ë™ ì‹œì‘ (ëŒ€í™” ë‚´ìš© ìë™ ì €ì¥ ì¤‘...)\n")
    
    while True:
        try:
            print("\n" + "="*40)
            # 1. ë“£ê¸°
            audio_file = record_voice_smart()
            if not audio_file: continue

            # 2. ì ê¸°
            user_text = speech_to_text(audio_file)
            print(f"ğŸ“ ì‚¬ìš©ì: {user_text}")

            if "ì¢…ë£Œ" in user_text:
                print("ğŸ‘‹ ë¹„ì„œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                # ì¢…ë£Œ ì „ì—ë„ ë¡œê·¸ ì €ì¥
                save_conversation(user_text, "ë¹„ì„œ ì¢…ë£Œ")
                break

            # 3. ìƒê°í•˜ê¸° (ë§ì´ ìˆì„ ë•Œë§Œ)
            if user_text.strip():
                ai_answer = ask_gpt(user_text)
                print(f"ğŸ¤– AI: {ai_answer}")

                # ğŸŒŸ [í•µì‹¬] ëŒ€í™” ë‚´ìš© íŒŒì¼ë¡œ ì €ì¥
                save_conversation(user_text, ai_answer)

                # 4. ë§í•˜ê¸°
                sound_file = text_to_speech(ai_answer)
                if sound_file:
                    playsound(sound_file)
                    time.sleep(0.5)
                    os.remove(sound_file) # ì„ì‹œ íŒŒì¼ ì‚­ì œ

        except KeyboardInterrupt:
            print("\nê°•ì œ ì¢…ë£Œ")
            break
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    ai_voice_assistant()