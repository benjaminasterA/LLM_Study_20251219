# ------------------------------------------------------------
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
# ------------------------------------------------------------
from openai import OpenAI
from dotenv import load_dotenv
import os
import sounddevice as sd
import scipy.io.wavfile as wav
import numpy as np
import time
from playsound import playsound

# ------------------------------------------------------------
# API ì´ˆê¸°í™”
# ------------------------------------------------------------
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ------------------------------------------------------------
# 1. ìë™ ë…¹ìŒ (ë§ ëë‚  ë•Œê¹Œì§€)
# ------------------------------------------------------------
def record_voice_auto(
    filename="input.wav",
    fs=16000,
    silence_threshold=300,      # í•œêµ­ì–´ ì¸ì‹ì— ë§ê²Œ íŠœë‹
    silence_duration=1.2
):
    print("\nğŸ¤ ì´ì œ ë§ì”€í•´ì£¼ì„¸ìš”! (ë§ ëë‚  ë•Œê¹Œì§€ ìë™ ë…¹ìŒ)\n")

    buffer = []
    silence_start = None
    recording = True
    frame_duration = 0.1  # 0.1ì´ˆì”© ë¶„ì„

    while recording:
        frame = sd.rec(int(frame_duration * fs), samplerate=fs, channels=1, dtype="int16")
        sd.wait()

        buffer.append(frame)
        volume = np.abs(frame).mean()

        # ğŸ”Š í•œêµ­ì–´ ë°œì„± ì¸ì‹ ê°•í™”
        if volume < silence_threshold:
            if silence_start is None:
                silence_start = time.time()
            elif time.time() - silence_start > silence_duration:
                print("ğŸ›‘ ë§ì´ ëë‚œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                recording = False
        else:
            silence_start = None

    audio = np.concatenate(buffer, axis=0)
    wav.write(filename, fs, audio)

    print("ğŸ§ ë…¹ìŒ ì™„ë£Œ:", filename)
    return filename


# ------------------------------------------------------------
# 2. Whisper â€” í•œêµ­ì–´ ìŒì„± ì¸ì‹
# ------------------------------------------------------------
def speech_to_text(file_path):
    with open(file_path, "rb") as f:
        result = client.audio.transcriptions.create(
            model="whisper-1",
            file=f
        )

    text = result.text
    print("ğŸ“ ì¸ì‹ëœ í•œêµ­ì–´:", text)
    return text


# ------------------------------------------------------------
# 3. GPT â€” í•œêµ­ì–´ ë‹µë³€ ìƒì„±
# ------------------------------------------------------------
def ask_gpt(question):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œë§Œ ëŒ€ë‹µí•˜ëŠ” ì¹œì ˆí•œ AI ìŒì„± ë¹„ì„œì…ë‹ˆë‹¤."},
            {"role": "user", "content": question}
        ]
    )

    answer = response.choices[0].message.content
    print("ğŸ¤– GPT ë‹µë³€:", answer)
    return answer


# ------------------------------------------------------------
# 4. TTSë¡œ ìŒì„± ìƒì„± (gpt-4o-mini-tts)
# ------------------------------------------------------------
def text_to_speech(text):
    output = f"reply_{int(time.time())}.mp3"

    speech = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text
    )

    with open(output, "wb") as f:
        f.write(speech.read())

    print("ğŸ”Š ìŒì„± ìƒì„± ì™„ë£Œ:", output)
    return output


# ------------------------------------------------------------
# 5. ì „ì²´ ìŒì„± ë¹„ì„œ ë£¨í”„
# ------------------------------------------------------------
def ai_voice_assistant():
    print("\nâœ¨ AI ìŒì„± ë¹„ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! (Ctrl+Cë¡œ ì¢…ë£Œ)\n")

    while True:
        print("\nğŸ¤ ì´ì œ ê³§ ë§ì”€í•´ì£¼ì„¸ìš”!")

        # ğŸ•’ 3ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´
        for i in range(3, 0, -1):
            print(f"â³ {i}ì´ˆ...")
            time.sleep(1)

        print("ğŸ™ ë…¹ìŒ ì‹œì‘!")

        # ìë™ ë…¹ìŒ
        audio_file = record_voice_auto()

        # ìŒì„± â†’ í…ìŠ¤íŠ¸
        user_text = speech_to_text(audio_file)

        # GPT ë‹µë³€ ìƒì„±
        answer = ask_gpt(user_text)

        # í…ìŠ¤íŠ¸ â†’ ìŒì„±
        sound_file = text_to_speech(answer)

        # ìŒì„± ì¬ìƒ
        playsound(sound_file)


# ------------------------------------------------------------
# ì‹¤í–‰
# ------------------------------------------------------------
if __name__ == "__main__":
    ai_voice_assistant()
