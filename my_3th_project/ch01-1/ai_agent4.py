# ğŸ“¦ [í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ëª…ë ¹ì–´]
# í„°ë¯¸ë„ì— ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì„œ í•„ìš”í•œ ë„êµ¬ë“¤ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.
# pip install openai python-dotenv sounddevice scipy numpy playsound fpdf2

import json  # ğŸ“„ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ì„ ë•Œ í‘œì¤€ í˜•ì‹ì¸ JSONì„ ì²˜ë¦¬í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
import random  # ğŸ² ë‚ ì”¨ë‚˜ ë‰´ìŠ¤ ì˜ˆì‹œë¥¼ ëœë¤ìœ¼ë¡œ ë½‘ê¸° ìœ„í•œ ë„êµ¬ì…ë‹ˆë‹¤.
from openai import OpenAI  # ğŸ¤– ì§€ëŠ¥í˜• AI(GPT)ì™€ ëŒ€í™”í•˜ê¸° ìœ„í•œ OpenAI ì „ìš© ë„êµ¬ì…ë‹ˆë‹¤.
from dotenv import load_dotenv  # ğŸ” ë¹„ë°€ë²ˆí˜¸(.env íŒŒì¼)ë¥¼ ì•ˆì „í•˜ê²Œ ë¶ˆëŸ¬ì˜¤ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
import os  # ğŸ’» íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ê±°ë‚˜ ìš´ì˜ì²´ì œ ê¸°ëŠ¥ì„ ì“°ê¸° ìœ„í•œ ë„êµ¬ì…ë‹ˆë‹¤.
import sounddevice as sd  # ğŸ¤ ë§ˆì´í¬ë¡œ ì†Œë¦¬ë¥¼ ë“£ê³  ë…¹ìŒí•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
import scipy.io.wavfile as wav  # ğŸ¼ ë…¹ìŒëœ ì†Œë¦¬ë¥¼ íŒŒì¼(.wav)ë¡œ ì €ì¥í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
import numpy as np  # ğŸ§® ì†Œë¦¬ íŒŒí˜•(ìˆ«ì)ì„ ê³„ì‚°í•˜ê³  ë¶„ì„í•˜ëŠ” ìˆ˜í•™ ë„êµ¬ì…ë‹ˆë‹¤.
import time  # â±ï¸ ì‹œê°„ì„ ì¬ê±°ë‚˜ ì ì‹œ ê¸°ë‹¤ë¦¬ê²Œ í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
from playsound import playsound  # ğŸ”Š MP3 íŒŒì¼ì„ ìŠ¤í”¼ì»¤ë¡œ ì¬ìƒí•´ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
from fpdf import FPDF  # ğŸ“‘ ì˜ˆìœ PDF ë³´ê³ ì„œë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ë„êµ¬ì…ë‹ˆë‹¤.

# ------------------------------------------------------------
# 0. API ì´ˆê¸°í™” (ì¤€ë¹„ ë‹¨ê³„)
# ------------------------------------------------------------
load_dotenv()  # ğŸ“‚ í”„ë¡œì íŠ¸ í´ë”ì˜ .env íŒŒì¼ì„ ì°¾ì•„ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤.
# ğŸ”‘ í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ êº¼ë‚´ì™€ì„œ OpenAI AIì™€ ì—°ê²°í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ------------------------------------------------------------
# 1. ë„êµ¬(í•¨ìˆ˜) ì •ì˜ - AIê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ë“¤
# ------------------------------------------------------------

def get_current_weather(location, unit="celsius"):
    """ [ì‹œë®¬ë ˆì´ì…˜] íŠ¹ì • ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ëŠ” ì²™í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. """
    print(f"ğŸ•µï¸ [System] '{location}'ì˜ ë‚ ì”¨ë¥¼ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤...")  # ğŸ” ë¡œê·¸ ì¶œë ¥
    conditions = ["ë§‘ìŒ â˜€ï¸", "íë¦¼ â˜ï¸", "ë¹„ ğŸŒ§ï¸", "ëˆˆ â„ï¸"]  # ğŸŒ¦ï¸ ë‚ ì”¨ ì˜ˆì‹œ
    return json.dumps({  # ğŸ“¦ ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ í¬ì¥í•´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
        "location": location,
        "temperature": random.randint(-5, 30),  # ğŸŒ¡ï¸ -5~30ë„ ì‚¬ì´ ëœë¤ ì˜¨ë„
        "condition": random.choice(conditions)  # ğŸ² ë‚ ì”¨ ì¤‘ í•˜ë‚˜ ëœë¤ ì„ íƒ
    })

def get_latest_news(topic="general"):
    """ [ì‹œë®¬ë ˆì´ì…˜] ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì²™í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. """
    print(f"ğŸ•µï¸ [System] '{topic}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...")  # ğŸ” ë¡œê·¸ ì¶œë ¥
    fake_headlines = [  # ğŸ“° ê°€ì§œ ë‰´ìŠ¤ ì œëª©ë“¤ (ì‹¤ì œ APIê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ êµì²´)
        f"ì†ë³´: {topic} ì‹œì¥, ì˜ˆìƒì„ ë›°ì–´ë„˜ëŠ” ì„±ì¥ ê¸°ë¡",
        f"ì „ë¬¸ê°€ë“¤ì´ ë§í•˜ëŠ” {topic}ì˜ ë¯¸ë˜ì™€ ì „ë§",
        f"ì „ ì„¸ê³„ê°€ ì£¼ëª©í•˜ëŠ” {topic}ì˜ í˜ì‹ ì ì¸ ë³€í™”",
        f"{topic} ê´€ë ¨ ìƒˆë¡œìš´ ê¸°ìˆ  í‘œì¤€ ë°œí‘œ ì„ë°•"
    ]
    return json.dumps({  # ğŸ“¦ ë‰´ìŠ¤ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        "topic": topic,
        "headlines": random.sample(fake_headlines, 3)  # ğŸ° 3ê°œë§Œ ë½‘ì•„ì„œ ì¤Œ
    })

def create_pdf_report(title, content):
    """ [PDF ìƒì„±] ê²€ìƒ‰í•œ ë‚´ìš©ì„ ê¹”ë”í•œ PDF íŒŒì¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. """
    print(f"ğŸ–¨ï¸ [System] PDF ë³´ê³ ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (ì œëª©: {title})")  # ğŸš€ ìƒì„± ì‹œì‘ ì•Œë¦¼
    
    filename = f"Report_{int(time.time())}.pdf"  # ğŸ•’ íŒŒì¼ëª…ì— ì‹œê°„ì„ ë„£ì–´ ê²¹ì¹˜ì§€ ì•Šê²Œ í•¨
    
    try:
        pdf = FPDF()  # ğŸ“„ ë¹ˆ PDF ë¬¸ì„œë¥¼ ë§Œë“­ë‹ˆë‹¤.
        pdf.add_page()  # â• ì¢…ì´ í•œ ì¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        # âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì • (ì¤‘ìš”: í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šìœ¼ë ¤ë©´ í°íŠ¸ê°€ í•„ìš”í•¨)
        # ìœˆë„ìš° ê¸°ë³¸ í°íŠ¸ ê²½ë¡œì…ë‹ˆë‹¤. ë§¥(Mac) ì‚¬ìš©ìëŠ” ê²½ë¡œ ë³€ê²½ì´ í•„ìš”í•©ë‹ˆë‹¤.
        font_path = "C:/Windows/Fonts/malgun.ttf" 
        
        if os.path.exists(font_path):  # âœ… í°íŠ¸ íŒŒì¼ì´ ì§„ì§œ ìˆëŠ”ì§€ í™•ì¸
            pdf.add_font("Malgun", fname=font_path)  # ğŸ“¥ í°íŠ¸ ë“±ë¡
            pdf.set_font("Malgun", size=12)  # ğŸ”¤ í°íŠ¸ ì„ íƒ ë° í¬ê¸° ì„¤ì •
        else:
            print("âš ï¸ [ê²½ê³ ] í•œê¸€ í°íŠ¸ê°€ ì—†ì–´ì„œ ê¸°ë³¸ í°íŠ¸ë¥¼ ì”ë‹ˆë‹¤. (í•œê¸€ ê¹¨ì§ ì£¼ì˜)")
            pdf.set_font("Helvetica", size=12)  # ğŸ”¤ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ì˜ì–´ í°íŠ¸ ì‚¬ìš©

        # ğŸ“Œ ì œëª© ì“°ê¸°
        pdf.set_font_size(16)  # ì œëª©ì´ë‹ˆê¹Œ ê¸€ìë¥¼ í‚¤ì›ë‹ˆë‹¤.
        # ê°€ìš´ë° ì •ë ¬(C)ë¡œ ì œëª©ì„ ì ìŠµë‹ˆë‹¤.
        pdf.cell(0, 10, text=f"Report: {title}", new_x="LMARGIN", new_y="NEXT", align='C')
        pdf.ln(10) # â†©ï¸ í•œ ì¤„ ë„ìš°ê¸°
        
        # ğŸ“ ë³¸ë¬¸ ì“°ê¸°
        pdf.set_font_size(11)  # ë³¸ë¬¸ ê¸€ì í¬ê¸°ë¡œ ì¤„ì…ë‹ˆë‹¤.
        pdf.multi_cell(0, 8, text=content)  # ğŸ“œ ê¸´ ê¸€ë„ ìë™ìœ¼ë¡œ ì¤„ë°”ê¿ˆí•´ì£¼ëŠ” í•¨ìˆ˜ ì‚¬ìš©
        
        pdf.output(filename)  # ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥
        print(f"âœ… PDF ì €ì¥ ì™„ë£Œ: {filename}")  # ğŸ‰ ì„±ê³µ ë©”ì‹œì§€
        
        # ğŸ“¨ AIì—ê²Œ ì„±ê³µí–ˆë‹¤ê³  ì•Œë ¤ì¤ë‹ˆë‹¤.
        return json.dumps({"status": "success", "filename": filename, "message": "íŒŒì¼ ìƒì„± ì™„ë£Œ"})

    except Exception as e:  # ğŸ’¥ ì—ëŸ¬ê°€ ë‚˜ë©´ í”„ë¡œê·¸ë¨ì´ êº¼ì§€ì§€ ì•Šê³  ì—¬ê¸°ë¡œ ì˜´
        print(f"âŒ PDF ìƒì„± ì‹¤íŒ¨: {e}")
        return json.dumps({"status": "error", "error": str(e)})

# ------------------------------------------------------------
# 2. AIì—ê²Œ ë„êµ¬ ì‚¬ìš©ë²• ì•Œë ¤ì£¼ê¸° (ì„¤ëª…ì„œ)
# ------------------------------------------------------------
tools_schema = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "ì§€ì—­ ë‚ ì”¨ ì¡°íšŒ",
            "parameters": {
                "type": "object",
                "properties": {"location": {"type": "string"}},
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_latest_news",
            "description": "ë‰´ìŠ¤ í‚¤ì›Œë“œ ê²€ìƒ‰",
            "parameters": {
                "type": "object",
                "properties": {"topic": {"type": "string"}},
                "required": ["topic"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "create_pdf_report",
            "description": "ì •ë³´ë¥¼ ìš”ì•½í•˜ì—¬ PDF íŒŒì¼ë¡œ ì €ì¥. ê²€ìƒ‰ í›„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ë‹¬ë¼ê³  í•  ë•Œ ì‚¬ìš©.",
            "parameters": {
                "type": "object",
                "properties": {
                    "title": {"type": "string", "description": "ë³´ê³ ì„œ ì œëª©"},
                    "content": {"type": "string", "description": "PDF ë³¸ë¬¸ ë‚´ìš©"}
                },
                "required": ["title", "content"]
            }
        }
    }
]

# ------------------------------------------------------------
# 3. [í•µì‹¬] ìŠ¤ë§ˆíŠ¸ ìŒì„± ë…¹ìŒ (VAD ê¸°ëŠ¥)
# ------------------------------------------------------------
def record_voice_smart(filename="input.wav", fs=16000, silence_threshold=150, silence_duration=1.2):
    """
    ğŸ¤ ëª©ì†Œë¦¬ê°€ ë“¤ë¦´ ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ë‹¤ê°€, ë§ì´ ì‹œì‘ë˜ë©´ ë…¹ìŒí•˜ê³ ,
       ë§ì´ ëë‚˜ê³  ì¡°ìš©í•´ì§€ë©´ ìë™ìœ¼ë¡œ ë…¹ìŒì„ ë©ˆì¶”ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    print("\nğŸ‘‚ ë“£ê³  ìˆì–´ìš”... ë§ì”€í•´ ë³´ì„¸ìš”! (ëª©ì†Œë¦¬ë¥¼ ê°ì§€í•˜ë©´ ë…¹ìŒ ì‹œì‘)")
    
    buffer = []  # ğŸ¥£ ì†Œë¦¬ ë°ì´í„°ë¥¼ ë‹´ì„ ë°”êµ¬ë‹ˆ
    recording = True  # âºï¸ ë…¹ìŒ ë£¨í”„ ì œì–´ìš© ê¹ƒë°œ
    voice_detected = False  # ğŸ—£ï¸ ë§ì„ ì‹œì‘í–ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê¹ƒë°œ
    silence_start_time = None  # ğŸ”‡ ì¹¨ë¬µì´ ì‹œì‘ëœ ì‹œê°„
    
    # ğŸ§ ë§ˆì´í¬ë¥¼ ì¼­ë‹ˆë‹¤ (InputStream)
    with sd.InputStream(samplerate=fs, channels=1, dtype="int16") as stream:
        while recording:
            # ğŸµ 0.1ì´ˆ ë¶„ëŸ‰ì˜ ì†Œë¦¬ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
            frame, _ = stream.read(int(0.1 * fs))
            
            # ğŸ”Š ì†Œë¦¬ì˜ í¬ê¸°(ì—ë„ˆì§€)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            volume = np.sqrt(np.mean(frame.astype(np.float64)**2))
            
            # --- ë¡œì§: ì†Œë¦¬ ê°ì§€ ë° ë…¹ìŒ ì œì–´ ---
            if volume > silence_threshold:  # ğŸ“¢ ì„¤ì •í•œ ê¸°ì¤€ë³´ë‹¤ ì†Œë¦¬ê°€ í¬ë‹¤ë©´? (ë§í•˜ëŠ” ì¤‘)
                if not voice_detected:
                    print("ğŸ—£ï¸ ê°ì§€ë¨! ë…¹ìŒ ì¤‘...")  # ğŸš¨ í™”ë©´ì— í‘œì‹œ
                    voice_detected = True  # ë§í•˜ê¸° ì‹œì‘í–ˆë‹¤ê³  í‘œì‹œ
                
                silence_start_time = None  # ë§í•˜ê³  ìˆìœ¼ë‹ˆ ì¹¨ë¬µ íƒ€ì´ë¨¸ ë¦¬ì…‹
                buffer.append(frame)  # ì†Œë¦¬ë¥¼ ë°”êµ¬ë‹ˆì— ë‹´ìŒ
                
            else:  # ğŸ¤« ì†Œë¦¬ê°€ ê¸°ì¤€ë³´ë‹¤ ì‘ë‹¤ë©´? (ì¡°ìš©í•¨)
                if voice_detected:  # ğŸ—£ï¸ ì´ë¯¸ ë§ì„ ì‹œì‘í•œ ìƒíƒœë¼ë©´?
                    if silence_start_time is None:
                        silence_start_time = time.time()  # â±ï¸ ì¹¨ë¬µ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                    
                    buffer.append(frame)  # ë§ì´ ëŠê¸°ì§€ ì•Šê²Œ ì¡°ìš©í•œ ë¶€ë¶„ë„ ì¼ë‹¨ ë‹´ìŒ
                    
                    # â³ ì¡°ìš©í•œ ì‹œê°„ì´ ì„¤ì •ê°’(1.2ì´ˆ)ì„ ë„˜ì—ˆëŠ”ì§€ í™•ì¸
                    if time.time() - silence_start_time > silence_duration:
                        print("âœ… ë§ì”€ì´ ëë‚˜ì„œ ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        recording = False  # ë…¹ìŒ ì¢…ë£Œ!
                else:
                    # ğŸ’¤ ì•„ì§ ë§ì„ ì‹œì‘ ì•ˆ í–ˆìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  ëŒ€ê¸° (ë²„í¼ì— ì•ˆ ë‹´ìŒ)
                    pass

    # ğŸ’¾ ëª¨ì€ ì†Œë¦¬ ì¡°ê°ë“¤ì„ í•©ì³ì„œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    if buffer:
        wav.write(filename, fs, np.concatenate(buffer, axis=0))
        return filename
    return None

def speech_to_text(file_path):
    """ ğŸ“ ë…¹ìŒëœ íŒŒì¼ì„ OpenAI Whisperì—ê²Œ ë³´ë‚´ ê¸€ìë¡œ ë°”ê¿”ì˜¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. """
    if not os.path.exists(file_path): return ""  # íŒŒì¼ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
    try:
        with open(file_path, "rb") as f:
            # ğŸŒªï¸ STT ëª¨ë¸(Whisper) í˜¸ì¶œ
            return client.audio.transcriptions.create(model="whisper-1", file=f, language="ko").text
    except: return ""

# ------------------------------------------------------------
# 4. GPT ë‘ë‡Œ (ìƒê°í•˜ê³  ë„êµ¬ ì“°ê¸°)
# ------------------------------------------------------------
def ask_gpt(question):
    """ ğŸ§  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ GPTì—ê²Œ ì „ë‹¬í•˜ê³ , ë„êµ¬ê°€ í•„ìš”í•˜ë©´ ì“°ê³ , ìµœì¢… ë‹µì„ ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. """
    
    # ğŸ“œ ëŒ€í™”ì˜ ë¬¸ë§¥(ê¸°ë¡)ì„ ë§Œë“­ë‹ˆë‹¤.
    messages = [
        {
            "role": "system",
            # ğŸ¯ AIì—ê²Œ ì •ì²´ì„±ê³¼ ì¼í•˜ëŠ” ìˆœì„œë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.
            "content": "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ë¹„ì„œì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ 'PDF ì €ì¥'ì„ ìš”ì²­í•˜ë©´ [ê²€ìƒ‰ -> ìš”ì•½ -> PDF ìƒì„±] ìˆœì„œë¡œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ í•˜ì„¸ìš”."
        },
        {"role": "user", "content": question}
    ]

    try:
        # 1ï¸âƒ£ GPTì—ê²Œ 1ì°¨ ì§ˆë¬¸ (ë„êµ¬ë¥¼ ì“¸ì§€ ë§ì§€ ê²°ì •)
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # ğŸš€ ë¹ ë¥´ê³  ë˜‘ë˜‘í•œ ëª¨ë¸
            messages=messages,
            tools=tools_schema,  # ğŸ§° ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
            tool_choice="auto"   # ğŸ¤– ì•Œì•„ì„œ íŒë‹¨í•´ë¼
        )
        
        response_message = response.choices[0].message
        tool_calls = response_message.tool_calls

        # ğŸ› ï¸ GPTê°€ "ë„êµ¬ë¥¼ ì¨ì•¼ê² ì–´ìš”!"ë¼ê³  í–ˆë‹¤ë©´?
        if tool_calls:
            print(f"ğŸ¤– GPT: {len(tool_calls)}ê°€ì§€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤...")
            messages.append(response_message)  # ëŒ€í™” íë¦„ì— ì¶”ê°€

            # ğŸƒâ€â™‚ï¸ GPTê°€ ì‹œí‚¨ ë„êµ¬ë“¤ì„ í•˜ë‚˜ì”© ì‹¤í–‰í•©ë‹ˆë‹¤.
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                tool_result = ""
                
                # ì–´ë–¤ ë„êµ¬ì¸ì§€ í™•ì¸í•˜ê³  ì‹¤í–‰
                if function_name == "get_current_weather":
                    tool_result = get_current_weather(function_args.get("location"))
                elif function_name == "get_latest_news":
                    tool_result = get_latest_news(function_args.get("topic"))
                elif function_name == "create_pdf_report":
                    tool_result = create_pdf_report(
                        function_args.get("title"), 
                        function_args.get("content")
                    )

                # ğŸ“¥ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëŒ€í™” ëª©ë¡ì— ì¶”ê°€í•´ì¤ë‹ˆë‹¤.
                messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": tool_result,
                })

            # 2ï¸âƒ£ ë„êµ¬ ê²°ê³¼ë¥¼ ë‹¤ ë³´ê³  ìµœì¢… ë‹µë³€ ìƒì„±
            second_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
            return second_response.choices[0].message.content
        
        else:
            # ğŸ’¬ ë„êµ¬ê°€ í•„ìš” ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë‹µë³€ ë°˜í™˜
            return response_message.content

    except Exception as e:
        print(f"âŒ GPT ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•´ìš”, ìƒê°í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”."

# ------------------------------------------------------------
# 5. ë§í•˜ê¸° ë° ë©”ì¸ ì‹¤í–‰
# ------------------------------------------------------------
def text_to_speech(text):
    """ ğŸ”Š AIì˜ í…ìŠ¤íŠ¸ ë‹µë³€ì„ ëª©ì†Œë¦¬ íŒŒì¼(MP3)ë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. """
    try:
        # ğŸ—£ï¸ OpenAI TTS ì‚¬ìš© (ëª©ì†Œë¦¬: nova)
        speech = client.audio.speech.create(model="tts-1", voice="nova", input=text)
        filename = f"reply_{int(time.time())}.mp3"
        with open(filename, "wb") as f:
            f.write(speech.read())
        return filename
    except: return None

def ai_voice_assistant():
    """ ğŸš€ í”„ë¡œê·¸ë¨ì˜ ì‹œì‘ì  (ë©”ì¸ ë£¨í”„) """
    print("\nğŸš€ [AI ìŒì„± ë¹„ì„œ]ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. (ë‰´ìŠ¤/ë‚ ì”¨/PDF ê¸°ëŠ¥ íƒ‘ì¬)\n")
    
    while True:  # â™¾ï¸ ë¬´í•œ ë°˜ë³µ (ê³„ì† ëŒ€í™”)
        try:
            print("\n" + "="*40)
            
            # 1. ğŸ¤ ë“£ê¸° (ìŠ¤ë§ˆíŠ¸ ë…¹ìŒ)
            audio_file = record_voice_smart()
            if not audio_file: continue  # ë…¹ìŒëœ ê²Œ ì—†ìœ¼ë©´ ë‹¤ì‹œ ëŒ€ê¸°

            # 2. ğŸ“ ë°›ì•„ì ê¸° (STT)
            user_text = speech_to_text(audio_file)
            print(f"ğŸ“ ì‚¬ìš©ì: {user_text}")

            # ğŸ‘‹ ì¢…ë£Œ ëª…ë ¹ì–´ í™•ì¸
            if "ì¢…ë£Œ" in user_text:
                print("ğŸ‘‹ ë¹„ì„œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                bye_sound = text_to_speech("ë„¤, ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”.")
                playsound(bye_sound)
                break  # ë£¨í”„ íƒˆì¶œ

            # 3. ğŸ§  ìƒê°í•˜ê³  ë‹µí•˜ê¸° (GPT + Tools)
            if user_text.strip():  # ë§ì´ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´
                ai_answer = ask_gpt(user_text)
                print(f"ğŸ¤– AI: {ai_answer}")

                # 4. ğŸ”Š ë§í•˜ê¸° (TTS)
                sound_file = text_to_speech(ai_answer)
                if sound_file:
                    playsound(sound_file)
                    time.sleep(0.5)
                    os.remove(sound_file) # ğŸ§¹ ë‹¤ ë“¤ì€ íŒŒì¼ ì‚­ì œ (ê¹”ë”í•˜ê²Œ)

        except KeyboardInterrupt:
            print("\nê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ê°€ ë‚˜ë„ êº¼ì§€ì§€ ì•Šê³  ë‹¤ì‹œ ë“£ê¸° ëª¨ë“œë¡œ

if __name__ == "__main__":
    ai_voice_assistant()  # ğŸ¬ í! ì•¡ì…˜!